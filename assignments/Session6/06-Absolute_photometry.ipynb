{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css_file = '../../styles/styles.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Absolute Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"objectives panel panel-warning\">\n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-certificate\"></span>&nbsp;Learning Objectives</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> * How to use the ``photutils`` library to detect sources on an image, and measure instrumental magnitudes for many stars\n",
    "> * Use the ```astroquery``` and ```astropy``` librarys to cross match catalogs on sky position\n",
    "> * How to compute zeropoints and uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the [lecture](http://slittlefair.staff.shef.ac.uk/teaching/phy241/lectures/L07/index.html) we learnt the theory behind precise calibration of photometry, enabling us to put photometric observations onto a standard scale with precisions of better than 1%. In this practical we are going to learn how to produce calibrated photometry using a **simplified method**. This method does not yield the same accuracy as an analysis using observations of primary or secondary standard stars, combined with the use of colour terms. On the other hand, it is much simpler to apply, and even works to produce calibrated photometry through thin cloud. If you are happy to accept accuracies on the order of a few percent, I recommend using the method described below whenever you need to produce calibrated photometry. \n",
    "\n",
    "In this practical we will will produce a colour-magnitude diagrams using the stacked images you made of your open cluster in the previous practical. If you have not yet finished that practical, use the stacked images provided in the ```data``` folder, taken from the open cluster NGC 7789. If you have finished, upload your own stacked images to the ```data``` folder and use them instead.\n",
    "\n",
    "## Method\n",
    "\n",
    "In the lecture we saw that, for any star, the difference between the calibrated magnitude, $m$ and the above-atmosphere instrumental magnitude $m_{0,i}$ is given by:\n",
    "$$m = m_{0,i} + m_{\\rm zp},$$\n",
    "where $m_{\\rm zp}$ is known as the zero point. The above-atmosphere instrumental magnitude is given by:\n",
    "$$m_{0,i} = m_i - kX,$$\n",
    "where $m_i = -2.5 \\log_{10} \\left( N_t/t_{\\rm exp} \\right)$ is the instrumental magnitude, $k$ is the extinction coefficient, and $X$ is the airmass. Therefore:\n",
    "$$m = m_i - kX + m_{\\rm zp}.$$\n",
    "In other words, if we were to plot the calibrated magnitude $m$ against instrumental magnitude $m_i$ for all the stars in our image, we would expect a straight line, with a gradient of one, and an intercept equal to $ -kX + m_{\\rm zp} $. **This intercept could then be added to all of our instrumental magnitudes to produce calibrated magnitudes.**\n",
    "\n",
    "What makes this technique possible, is the existence of large sky surveys, which have provided calibrated magnitudes for many, relatively bright stars over a very wide areas of the sky. If your data is covered by one of these surveys, and it provides calibrated magnitudes in the same filter as your data, you can apply this technique relatively quickly.\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "The accuracy this technique can achieve is limited by two factors. First of all we are not taking into account any secondary effects, such as 2nd-order extinction, or colour terms. Secondly, our photometry cannot be any more accurate than that in the sky survey we use. Typically, large sky surveys achieve accuracies of a few percent. Ignoring the secondary effects will probably introduce errors on a similar level. If you need calibrated photometry to better than a few percent, you will have to observe standard stars, and apply the rigorous method described in the lecture.\n",
    "\n",
    "## Steps\n",
    "\n",
    "Applying this method requires the application of four steps. These steps are:\n",
    "\n",
    "1. finding the stars in our image, and calculating instrumental magnitudes;\n",
    "1. matching our stars against a sky-survey, so we know instrumental and calibrated magnitude for many stars;\n",
    "1. calculating the offset between instrumental and calibrated magnitudes, and applying to all stars in our image.\n",
    "\n",
    "\n",
    "We will carry out these steps in Python. As usual we will draw on several third-party Python libraries. I will explain their use, and provide links to detailed documentation. We will also use some code that I have written which will help ease the code writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Photometry with Photutils\n",
    "\n",
    "We have done aperture photometry [before](http://slittlefair.staff.shef.ac.uk/teaching/phy241/practicals/P05/index.html), using AstroImageJ. Whilst this tool is excellent for relative photometry, and producing light curves, each aperture must be placed by hand, which makes it onerous to use when we want to measure every star in an image. \n",
    "\n",
    "There are a lot of steps to aperture photometry. We must detect stars in the image, and measure their positions accurately. Then we have to add up the counts within a *target aperture*. Finally we have to measure the sky background level in a *sky annulus*, and subtract off the sky background. You can imagine that writing the functions to do this from scratch is going to be hard. Thankfully, there is a Python library called [photutils](http://photutils.readthedocs.org/en/latest/) that is written to do exactly this. \n",
    "\n",
    "Photutils is not installed by default on CoCalc. The code cell below will install it. Run this cell, and if there are any **errors**, ask for help (warnings are ok)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install photutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## if this code cell runs without error, you have successfully installed photutils!\n",
    "import photutils as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Read in your image</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "Using the code cell below, read in your 300s, V-band stacked image into an array called `data`. Read the header from the FITS file into a variable called `header`. It's important to use those variable names - I'll assume they exist later in the notebook.\n",
    "\n",
    "You can look at the code from Session 5 about the `astropy.io.fits` library if you can't remember how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Creating a Source List</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "Our first job is to detect our sources. We will do this using an algorithm called DAOFIND ([Stetson 1987, PASP, 99, 191](https://ui.adsabs.harvard.edu/abs/1987PASP...99..191S/abstract)). DAOFIND looks for bright regions in the image that have a peak brightness greater than some threshold and that have a size and shape similar to a Gaussian of specified FWHM.\n",
    "\n",
    "Stars in our image will stand out above the background, and DAOFIND will find them, but we need to know what threshold to use. One way of doing this is to measure the statistics of the **background** in our image. If we measure the average value of the background, and the amount the background varies, we can look for regions that are significantly brighter than background pixels. \n",
    "\n",
    "Below I do that using a \"sigma-clipped\" mean - where I estimate the average background and the standard deviation. We then throw away all the pixels more than 3 standard deviations (sigma) away from the mean, and repeat the process. I carry on until no pixels are more than 3 standard deviations away from the average value. Then I calculate the mean, median and standard deviation of the remaining pixels. Sound complex? Don't worrry, there's already code to to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# import sigma_clipping function from astropy\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "mean_background, median_background, background_standard_deviation = sigma_clipped_stats(data, sigma=3.0)\n",
    "\n",
    "print(\"The background has an average value of {:.1f} and a standard deviation of {:.1f} counts\".format(\n",
    "    mean_background, background_standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finding Stars\n",
    "\n",
    "Now we know how bright our background is, and how much it varies, let's look for stars that are brighter than the background plus 5 standard deviations. That should be enough that we don't identify bright background pixels as stars by accident. The DAOFIND algorithm needs a guess for how big the stars are - as a Gaussian FWHM - we'll guess at 3 pixels for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from photutils import DAOStarFinder\n",
    "\n",
    "# make a star finder object to look for stars with FWHM~3 pixels that are more than 5-sigma above background\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=5*background_standard_deviation)\n",
    "\n",
    "# use it to find stars. We'll subtract the background off first, so background pixels have an average value of 0\n",
    "sources = daofind(data - median_background)\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The ``sources`` variable contains a table of all the detected stars. There are various columns, but the ones we are interested in is the X and Y positions of the stars, which you can find with ```sources['xcentroid']``` and ```sources['ycentroid']```.\n",
    "\n",
    "But how do we know we've found most of the stars? Or if we are mistakenly identifying bright background pixels as stars? We can inspect our sources by-eye. To make this easier, I've written a little helper function to plot your image with the sources overlaid. The function is in the file `photometry_helpers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from photometry_helpers import plot_sources\n",
    "help(plot_sources)\n",
    "    \n",
    "plot_sources(data, sources, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Tweak the detection settings</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> The DAOFIND algorithm requires a threshold for star detection, and a typical FWHM of the stars in the images. Try different settings for these values, and see how they affect the detection of stars in your data. Make a decision about what values to use for this image.\n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>FWHM of stars in the image</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "We will also need an estimate for the FWHM of stars in the image. We can estimate this by-eye by plotting a bright, isolated, star and plotting the brightness against distance from the star's centre. I've written a clever little routine to do this. \n",
    "\n",
    "Using the plot created by the code below, estimate the FWHM of the star in pixels. You should be able to convert this to a value in arcseconds, using the information you recorded during observing, and the specifications of the [Hicks Observatory](https://sites.google.com/sheffield.ac.uk/astronomy/hicks-observatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from photometry_helpers import measure_FWHM\n",
    "\n",
    "measure_FWHM(data, sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Aperture Photometry\n",
    "\n",
    "So, we have a list of detected sources and positions in the image, and an idea of the FWHM of stars in the image. Now we can perform aperture photometry on all of these sources. I've written a function to do this for us. The comments in the function make it relatively easy to understand, so by all means take a look in the file `photometry_helpers.py` to see what the function does if you like. In brief the function performs the following steps:\n",
    "\n",
    "1. Add up the counts from each source within a target aperture\n",
    "2. Measure the sky brightness around each source using the sky annulus\n",
    "3. Subtract the sky contribution from the counts in step 1.\n",
    "4. Calculate instrumental magnitude from the counts and exposure time.\n",
    "\n",
    "By now you should be getting quite good at reading documentation for functions you import, so let's import my function at look at the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from photometry_helpers import aperture_photometry\n",
    "help(aperture_photometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Perform Aperture Photometry</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "Using the help above, use this function to perform aperture photometry on all of your sources. You'll need to pick values for the aperture radii, remembering everything we've discussed in the course about how these choices affect the quality of your measurement. \n",
    "\n",
    "Target apertures want to be big enough to accept a decent fraction of the flux, but not so large that the measurements are very noisy, or contaminated by nearby stars. As a rule of thumb this aperture might have a radius of 1.5-2x the FWHM.\n",
    "\n",
    "Sky Annuli want to be wide enough to accurately measure the sky, but not so large that the annuli overlap nearby stars.\n",
    "\n",
    "To get started, try values around 5, 10, 20 pixels for these apertures. We will tweak them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE. USE THE FUNCTION ABOVE TO PERFORM APERTURE PHOTOMETRY\n",
    "\n",
    "# SAVE THE TABLE RETURNED IN A SUITABLY NAMED VARIABLE. Perhaps call it V300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Photometric Calibration\n",
    "\n",
    "Now we have a table of instrumental magnitudes (and much besides) in it. The next step is photometric calibration. As a reminder, this involves fitting a straight line to a graph of *instrumental magnitude* against *calibrated magnitude*, to find the offset between the two. Equivalently, we can find the average value of the *difference* between the calibrated and instrumental magnitudes for all our stars.\n",
    "\n",
    "Since we have instrumental magnitudes and sky positions (RA, Dec) for a number of stars, we must find the matching stars in an online catalog of calibrated magnitudes. We will use the [APASS](https://www.aavso.org/apass) catalog; a catalog which combines several other sky surveys to provide data in many filters across much of the sky. Crucially, in this case it includes B and V magnitudes, the two filters used for our photometry.\n",
    "\n",
    "To perform the cross-matching we will use the [astroquery](https://astroquery.readthedocs.io/en/latest/) Python library, and we have our aperture photometry results in a [Table](http://docs.astropy.org/en/stable/table/) object from [astropy](http://www.astropy.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from astropy import units as u\n",
    "from astroquery.xmatch import XMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Our photometry is stored as an astropy table, which is a handy object for reading and writing tabular data. These astropy tables play nicely with Jupyter notebooks, so you can simply type the name of the table in a code cell to see the table displayed in the browser. So, if you named your photometry table above ```V300``` the following cell will work. If not, replace the variable name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "V300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The important columns for our uses are the measured centres of our stars in RA and Dec (**RA** and **DEC**) and the instrumental magnitude and uncertainty (**instrumental_mag** and **e_instrumental_mag**). Note that the magnitude uncertainty is calculated using the CCD signal-to-noise equation we saw in the [lectures](http://slittlefair.staff.shef.ac.uk/teaching/phy241/lectures/L09/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>X-match with APASS</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> We need to calibrate our photometry, which will involve comparing our instrumental magnitudes to calibrated magnitudes measured for the same stars. We need to match our detected stars with those catalogued in the sky survey [APASS](https://www.aavso.org/apass). We are looking for stars who's RA and Dec matches to within some radius. A service called **Vizier** hosts online versions of astronomical catalogs, and we can use the ```Xmatch.query``` function to match an astropy table with a table hosted by Vizier using the code below.\n",
    "\n",
    "> Run the code cell below, and note carefully how we specify the columns that contain RA and Dec in our *local* table, and how we set the maximum distance for a valid match. **II/336/apass9** is the name of the APASS catalog on Vizier. If you need to find the names of other catalogs (perhaps APASS doesn't cover the patch of sky containing your open cluster), you can enter the catalog name in the search box [here](http://vizier.u-strasbg.fr)\n",
    "\n",
    "> **The code cell below may take a while to run. Be patient...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "xmatch = XMatch.query(cat1=V300, cat2='vizier:II/336/apass9', max_distance=2*u.arcsec, colRA1='RA', colDec1='DEC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The result of this query (```xmatch```) is also an astropy ```Table```. It has all the columns from both tables for each valid match. If you want to extract a column and save it into a variable, you can access the ```Table``` like a dictionary. So the code below extracts the **Magnitude** column (which is instrumental magnitude from our APT photometry) and **Vmag** column from UCAC4 and computes the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "delta_mag = xmatch['Vmag'] - xmatch['instrumental_mag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Plot the difference and find the zero-point</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Plot the difference between instrumental and calibrated magnitude found above, against the calibrated V-band magnitude on the X-axis. You should see something like the figure below:\n",
    "\n",
    "<img src=\"../../images/V_zeropoint.png\" style=\"margin: 0px\" width=750px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE - MAKE A PLOT LIKE THE ONE ABOVE. DON'T WORRY ABOUT ADDING THE HORIZONTAL LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The magnitude difference between instrumental and calibrated magnitude *should* be a constant, which is the value of $kX + m_{\\rm zp}$. In the figure above, you can see there are plenty of outlying points, and the bright stars deviate from the constant. The outliers are either stars whose photometry is bad (poor sky estimation, or contaminated by very close stars), or spurious detections (i.e not stars). The deviation of the bright stars is caused because they are [saturated](http://slittlefair.staff.shef.ac.uk/teaching/phy241/lectures/L06/index.html#readout), and so we cannot accurately measure their flux.\n",
    "\n",
    "Since $m = m_i - kX + m_{\\rm zp}$, we can find the value of $-kX + m_{\\rm zp}$. - which I'll call the *zeropoint* from now on - by calculating the **median** difference between the instrumental and calibrated magnitude. The median will be robust against the outliers - but we only want to do it for the non-saturated stars!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-pencil\"></span>Calculate the zero-point</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Calculate the median value of ```delta_mag```. **If you have evidence for saturated stars**, use a NumPy *mask* to only calculate the median of stars that are not saturated (see notes on Fancy slicing in the NumPy notebook).\n",
    "\n",
    "> The median value of ```delta_mag``` is our estimate of $-kX + m_{\\rm zp}$ - i.e the value we want to add to our instrumental magnitudes to get a calibrated magnitude. You can add this value to the **instrumental_mag** column of the V300 table easily using ```V300['calibrated_mag'] = V300['instrumental_mag'] + zp```, where ```zp``` is the median value you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE. CALCULATE THE ZEROPOINT AND ADD IT TO THE MAGNITUDE COLUMN OF THE V300 table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---------\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h1>Homework #6</h1>\n",
    "<h2><span class=\"fa fa-pencil\"></span>The B-band data and making a CMD</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Your task in the homework is to repeat the steps above for the rest of your data, and make two CMDs, one for the 30s data, and one for the 300s data.\n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-question\"></span>  The B-band data (4 points)</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Repeat the steps above for the 300-second B-band data. Make a plot of the difference between instrumental B-band magnitude and APASS B-band magnitude. Calculate the offset needed to correct your instrumental mags (zeropoint) and display it on your plot.\n",
    "\n",
    "> Finally, add your zeropoint to the **instrumental_mag** column of the 300s B-band table to make a new **calibrated_mag** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now you should have a two astropy tables in computer memory. One with corrected (calibrated) V-band magnitudes and one with corrected (calibrated) B-band magnitudes. We need to cross-match these tables with each other, to find which stars in the V-band table match with stars in the B-band table. We can't use ```astroquery```'s Xmatch for this, since they are both local tables. Instead, we will use the ```SkyCoord``` object from astropy, which is meant to work with coordinates on the sky. You can create a ```SkyCoord``` object with positions of all of the stars in a table like so:\n",
    "\n",
    "```python\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "coo_v = SkyCoord(V300['RA'], V300['DEC'], unit=u.deg)\n",
    "```\n",
    "\n",
    "The ```SkyCoord``` you made is a bit like a NumPy array, but it is an array of positions on the sky. It carries within it several useful functions, including one to match positions against another sky coordinate object - ```match_coordinates_sky```. It's usage is shown below, and the documentation is [here](http://docs.astropy.org/en/stable/coordinates/matchsep.html#matching-catalogs). ```match_coordinates_sky``` returns an array of indices and the 2D and 3D separations of the matches. The array of indices can be used as a slice to sort the second set of coordinates, or the table from which it came, so that each row of the sorted coordinate/table contains the closest match of the corresponding row. Perhaps an example will explain:\n",
    "\n",
    "```python\n",
    "# match every entry in coo_v with the nearest entry in coo_v\n",
    "idx, distance_2d, distance_3d = coo_v.match_to_catalog_sky(coo_b)\n",
    "\n",
    "# using idx as a slice for the table B300 will sort it so that B300[0] is the closest match to V300[0]\n",
    "B300 = B300[idx]\n",
    "```\n",
    "\n",
    "We are not quite done yet though - we have found the closest match to every object in the V300 table, but some of those matches may be quite far away. We could create a *fancy slicing mask* of True and False values by comparing the ```distance_2d``` array to some threshold separation, and use that mask to remove the rows where there is no close cross-match:\n",
    "\n",
    "```python\n",
    "mask = distance_2d < 3 * u.arcsec\n",
    "B300 = B300[mask]\n",
    "V300 = V300[mask]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-question\"></span>Cross-matching your V and B-band tables (2 points)<h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Create ```SkyCoord``` objects from your 300s B and V tables. Match them using ```match_coordinates_sky```, and use a mask to remove all rows where there is no good match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-question\"></span>Plotting your CMD (3 points)</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> With your matched tables in hand, extract the calibrated magnitude columns from each into two arrays called ```V``` and ```B```. Calculate ```B-V``` and plot a colour-magnitude diagram of ```B-V``` against ```V```. Your plot should look something like the one below, which is for the cluster NGC 7789.\n",
    "\n",
    "<img src=\"../../images/CMD.png\" style=\"margin: 0px\" width=750px/>\n",
    "\n",
    "> Also calculate error bars on ```B-V```: remember that $\\Delta (x+y)^2 = \\Delta x^2 + \\Delta y^2$\n",
    "\n",
    "> Hint: you can reverse the y-axis with ```plt.gca().invert_yaxis()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<h2><span class=\"fa fa-question\"></span>Save your data (1 point)</h2>\n",
    "</div>\n",
    "</section>\n",
    "\n",
    "> Save your ```V``` and ```B-V``` data, along with their uncertainties, to a text file, for use in the next lab!\n",
    "\n",
    "> You might want to revisit Session1 for instructions for writing data to a file. Or, you could create an astropy Table using the instructions [here](https://docs.astropy.org/en/stable/table/construct_table.html) and [here](https://docs.astropy.org/en/stable/table/io.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}